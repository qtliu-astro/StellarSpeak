# ğŸŒŒ StellarSpeakï¼ˆæ˜Ÿè¯­è€…ï¼‰â€”â€”å¤©æ–‡å­¦é¢†åŸŸä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹

> â€œè®©çŸ¥è¯†å¼€å£è¯´è¯â€ â€”â€” ä¸­å›½ç§‘å­¦é™¢å¤§å­¦ **æ˜Ÿè¯­è°ƒæ ¡å±€** å‡ºå“

---

## ğŸ“– ç®€ä»‹

**StellarSpeakï¼ˆæ˜Ÿè¯­è€…ï¼‰** æ˜¯ç”±ä¸­å›½ç§‘å­¦é™¢å¤§å­¦ **æ˜Ÿè¯­è°ƒæ ¡å±€** è®¾è®¡ä¸è®­ç»ƒçš„ 13B çº§æ™ºèƒ½è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸º**å¤©æ–‡å­¦ã€ç§‘å­¦é—®ç­”ä¸æ•°ç†æ¨ç†**åœºæ™¯å¼€å‘ã€‚æ¨¡å‹åŸºäºä¸­ç§‘é™¢è®¡ç®—æ‰€å‘å¸ƒçš„ **BayLing-13B** åŸºåº§ï¼Œç»“åˆå‚æ•°é«˜æ•ˆçš„ **LoRA æŠ€æœ¯**ï¼Œåœ¨è¶…è¿‡ 30 ä¸‡æ¡é«˜è´¨é‡è‡ªæ„å¤©æ–‡è¯­æ–™ä¸ Alpaca é€šç”¨æŒ‡ä»¤è¯­æ–™åŸºç¡€ä¸Šå®Œæˆå¾®è°ƒè®­ç»ƒã€‚

**ä¸»è¦èƒ½åŠ›ï¼š**

- ğŸ”­ å¤©æ–‡å­¦çŸ¥è¯†é—®ç­”ä¸ç ”ç©¶æ”¯æŒ  
- ğŸ“ æ•°å­¦/ç‰©ç†æ¨ç†ä¸é€šè¯†ä»»åŠ¡  
- ğŸ§  è‡ªæˆ‘è®¤çŸ¥ä¸å¤šè½®æŒ‡ä»¤å“åº”  
- ğŸŒ ä¸­è‹±æ–‡åŒè¯­ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›

---

## ğŸ§  æ¨¡å‹æ¶æ„

- **åŸºåº§æ¨¡å‹**ï¼šBayLing-13Bï¼ˆåŸºäº LLaMA2 æ¶æ„ï¼‰
- **å¾®è°ƒæ–¹å¼**ï¼šLoRAï¼ˆLow-Rank Adaptationï¼‰
- **æƒé‡è®¾è®¡**ï¼šå†»ç»“åŸå§‹å‚æ•°ï¼Œä»…ä¼˜åŒ–å°‘é‡ä½ç§©çŸ©é˜µï¼ŒèŠ‚çœè®­ç»ƒèµ„æº
- **éƒ¨ç½²æ–¹å¼**ï¼šæ”¯æŒ 8bit/16bit åŠ è½½ï¼Œå…¼å®¹ HuggingFace

---

## ğŸ’» æœ¬åœ°éƒ¨ç½²æ•™ç¨‹

### 1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡

```bash
conda create -n stellar python=3.10
conda activate stellar 
```

### 2ï¸âƒ£ ä¸‹è½½åŸºåº§æ¨¡å‹ BayLing

åœ¨ç›¸åº” HuggingFace ä»“åº“ä¸­ä¸‹è½½åŸºåº§æ¨¡å‹å‚æ•°æ–‡ä»¶ï¼Œå¹¶å‘½åä¸ºï¼š

- bayling-2-7b/ æˆ– bayling-13b/

æºä»“åº“åœ°å€ï¼šhttps://huggingface.co/ICTNLP/bayling-2-7b

### 3ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
pip install -U torch torchvision torchaudio transformers accelerate protobuf==3.19.0
```

### 4ï¸âƒ£ å¯åŠ¨äº¤äº’æœåŠ¡ï¼ˆä»¥ 7B ä¸ºä¾‹ï¼‰

```bash
python chat.py --model-path ./bayling-2-7b --style rich --load-8bit
```
![è¾“å…¥å›¾ç‰‡è¯´æ˜](figs%E6%88%AA%E5%B1%8F2025-07-09%2015.39.29.png)


---


## ğŸ§¾ è‡ªè®­è¯­æ–™æ„å»º

æˆ‘ä»¬æ„å»ºäº†åŒ…å«**é€šç”¨æŒ‡ä»¤ä»»åŠ¡**ã€**å¤©æ–‡ä¸æ•°å­¦é¢†åŸŸä»»åŠ¡**ã€**æ¨¡å‹è‡ªæˆ‘è®¤çŸ¥**ä¸‰å¤§ç±»çš„é«˜è´¨é‡è®­ç»ƒè¯­æ–™ã€‚

ğŸ“ æ‰€æœ‰è¯­æ–™å·²å¼€æºå‘å¸ƒåœ¨ï¼š

ğŸ‘‰ https://huggingface.co/TQLLab/StellarSpeak_13B_LLM/tree/main/dataset
![è¾“å…¥å›¾ç‰‡è¯´æ˜](%E6%88%AA%E5%B1%8F2025-07-09%2016.45.05.png)

ğŸ“„ æ•°æ®æ ¼å¼ä¸ºä¸‰å…ƒç»„ç»“æ„ï¼š

```json
{
  "instruction": "ä½ æ˜¯ä¸€ä½èµ„æ·±å¤©æ–‡å­¦å®¶ï¼Œè¯·è®¤çœŸåˆ†æå¹¶å›ç­”ä¸‹åˆ—é—®é¢˜ã€‚ å‡è®¾ä½ æ˜¯ä¸€ä½å¤©æ–‡å­¦å®¶ã€‚ä»¥ä¸‹æ˜¯ä¸€é“ã€å¤©æ–‡æŠ€æœ¯ä¸æ–¹æ³•ã€‘æ–¹å‘çš„ç®€ç­”é¢˜ï¼Œè¯·ç®€è¦å›ç­”é—®é¢˜ï¼Œçªå‡ºé‡ç‚¹ã€‚",
  "input": "æœ‰äººè¯´â€œåæŒ¯å…‰æœ‰ä»€ä¹ˆåº”ç”¨åœºæ™¯ï¼Ÿâ€ï¼Œä½ æ€ä¹ˆçœ‹ï¼Ÿ",
  "output": "è§£é‡Šå¦‚ä¸‹ï¼šåå…‰å¼3DæŠ€æœ¯æ™®éç”¨äºå•†ä¸šå½±é™¢å’Œå…¶å®ƒé«˜ç«¯åº”ç”¨ï¼Œå®ƒæ˜¯åæŒ¯å…‰çš„å…¸å‹åº”ç”¨ã€‚åœ¨æŠ€æœ¯æ–¹å¼ä¸Šå’Œå¿«é—¨å¼æ˜¯ä¸€æ ·çš„ï¼Œå…¶ä¸åŒçš„æ˜¯è¢«åŠ¨æ¥æ”¶æ‰€ä»¥ä¹Ÿè¢«ç§°ä¸ºå±äºè¢«åŠ¨å¼3DæŠ€æœ¯ï¼Œè¾…åŠ©è®¾å¤‡æ–¹é¢çš„æˆæœ¬è¾ƒä½ï¼Œä½†å¯¹è¾“å‡ºè®¾å¤‡çš„è¦æ±‚è¾ƒé«˜ï¼Œæ‰€ä»¥éå¸¸é€‚åˆå•†ä¸šå½±é™¢ç­‰éœ€è¦ä¼—å¤šè§‚ä¼—çš„åœºæ‰€ä½¿ç”¨ã€‚"
}
```

ğŸ“Œ **æ•°æ®åˆå¹¶è¯´æ˜ï¼š**

- é€šç”¨ + ä¸“ä¸š + è‡ªæˆ‘è®¤çŸ¥è¯­æ–™ç»Ÿä¸€æ•´åˆä¸ºä¸€ä¸ª `.json` æ–‡ä»¶ç”¨äºè®­ç»ƒï¼›
- è‹¥æŸç±»æ•°æ®æ•°é‡æ˜æ˜¾åå°‘ï¼Œå¯é€šè¿‡å¤åˆ¶æ‰©å……å…¶æ¯”ä¾‹ï¼Œé˜²æ­¢è®­ç»ƒä¸­è¢«å¿½è§†ã€‚

ğŸ’¡ **TIPï¼š** ä¸åŒ Prompt æ¨¡æ¿ä¼šå¯¼è‡´å¾®å°æ€§èƒ½å·®å¼‚ï¼Œç›¸å…³å®éªŒåˆ†æè§ï¼š[Astro-QA](https://github.com/ACMISLab/Astro-QA)

![è¾“å…¥å›¾ç‰‡è¯´æ˜](%E6%88%AA%E5%B1%8F2025-07-09%2016.46.25.png)
![è¾“å…¥å›¾ç‰‡è¯´æ˜](%E6%88%AA%E5%B1%8F2025-07-09%2016.46.31.png)
---


## ğŸ”§ LoRA å¾®è°ƒæ­¥éª¤

### 1ï¸âƒ£ å…‹éš†å¾®è°ƒæ¡†æ¶

```bash
git clone https://github.com/tloen/alpaca-lora.git
cd alpaca-lora
```

### 2ï¸âƒ£ å®‰è£…ä¾èµ–

ç¼–è¾‘ `requirements.txt`ï¼Œåˆ é™¤ï¼š

```diff
- git+https://github.com/huggingface/peft.git
```

ç„¶åæ‰§è¡Œï¼š

```bash
pip install -r requirements.txt
pip install scipy peft pytest pyyaml
pip install datasets==2.10.1 fsspec==2023.9.2 transformers==4.44.2
```

### 3ï¸âƒ£ é…ç½®æŒ‡ä»¤æ¨¡æ¿

åœ¨ `alpaca-lora` ä»“åº“ä¸­çš„æ–‡ä»¶å¤¹ä¸­æ–°å»ºæ–‡ä»¶ `templates/bayling.json`ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```json
{
  "description": "Template used by æ˜Ÿè¯­è€…ï¼ˆStellarSpeakï¼‰.",
  "prompt_input": "I am an intelligent language assistant developed by æ˜Ÿè¯­è°ƒæ ¡å±€ã€‚\nBelow is a dialog consisting of instructions and responses. Write a response that completes the request.\n\n### Instruction:\n{instruction} {input}\n### Response:\n",
  "prompt_no_input": "I am an intelligent language assistant developed by æ˜Ÿè¯­è°ƒæ ¡å±€ã€‚\nBelow is a dialog consisting of instructions and responses. Write a response that completes the request.\n\n### Instruction:\n{instruction}\n### Response:\n",
  "response_split": "### Response:"
}
```

### 4ï¸âƒ£ å¾®è°ƒè„šæœ¬å‚è€ƒ

```bash
# è®¾ç½®ä½¿ç”¨çš„ GPU
export CUDA_VISIBLE_DEVICES=0

# å¯åŠ¨å¾®è°ƒè„šæœ¬
python /home/jovyan/data/alpaca-lora-main/finetune.py \
  --base_model '/home/jovyan/data/bayling_model/bayling-13b' \
  --data_path '/home/jovyan/data/train_js/train_dataset.json' \
  --output_dir '/home/jovyan/data/fine_model/v1' \
  --batch_size 256 \
  --micro_batch_size 2 \
  --num_epochs 3 \
  --learning_rate 1e-4 \
  --cutoff_len 256 \
  --lora_r 8 \
  --lora_alpha 16 \
  --lora_dropout 0.05 \
  --lora_target_modules '[q_proj,k_proj,v_proj,o_proj]' \
  --train_on_inputs False \
  --prompt_template_name '/home/jovyan/data/alpaca-lora-main/templates/bayling' \
  --group_by_length
```

ğŸ“Œ **èµ„æºéœ€æ±‚è¯´æ˜ï¼š**

| æ¨¡å‹ç‰ˆæœ¬ | cutoff_len | micro_batch_size | æ˜¾å­˜éœ€æ±‚ |
|----------|------------|------------------|-----------|
| 7B       | 512        | 4                | â‰ˆ 50 GB   |
| 13B      | 256        | 2                | â‰ˆ 80 GB   |

---


## ğŸ›°ï¸ æ˜Ÿè¯­è€…æ¨¡å‹å‘å¸ƒä¿¡æ¯

æˆ‘ä»¬å·²ç»å°†è®­ç»ƒå®Œæˆçš„ **æ˜Ÿè¯­è€…-13B** æ¨¡å‹å¼€æºå‘å¸ƒï¼Œ**å½“å‰å‘å¸ƒç‰ˆæœ¬ä¸ºæœªä¸åŸºåº§æ¨¡å‹åˆå¹¶çš„ LoRA å¾®è°ƒæƒé‡**ï¼Œéœ€æ‰‹åŠ¨ä¸ BayLing-13B è¿›è¡Œåˆå¹¶ã€‚

ğŸ“¦ æ¨¡å‹ä»“åº“åœ°å€ï¼š

ğŸ‘‰ https://huggingface.co/TQLLab/StellarSpeak_13B_LLM
![è¾“å…¥å›¾ç‰‡è¯´æ˜](%E6%88%AA%E5%B1%8F2025-07-09%2016.47.38.png)

åŒ…å«å†…å®¹ï¼š


- 13BSS_model_tensors/v3/ï¼šLoRA å¾®è°ƒæƒé‡ï¼ˆadapter æ¨¡å‹ï¼‰
- dataset/ï¼šè®­ç»ƒæ‰€ç”¨æŒ‡ä»¤è¯­æ–™
- README.mdï¼šä½¿ç”¨è¯´æ˜
---

## ğŸ”— æ¨¡å‹åˆå¹¶ä¸å¯¼å‡º
å°† LoRA æƒé‡ä¸åŸºåº§æ¨¡å‹åˆå¹¶ä¸º HuggingFace æ ¼å¼å®Œæ•´æ¨¡å‹ï¼š

```bash
python /home/jovyan/data/alpaca-lora-main/export_hf_checkpoint.py \
	--base-model /home/jovyan/data/bayling_model/bayling-13b \
	--lora-model /home/jovyan/data/fine_model/v1/checkpoint-4068 \
	--output-model /home/jovyan/data/StellarSpeak/v1

```
åˆå¹¶åå¯ç›´æ¥ç”¨äºæ¨ç†æˆ–éƒ¨ç½²ã€‚


---

## ğŸ“Š æ¨¡å‹æµ‹è¯•ä¸æ€§èƒ½è¯„ä¼°

- æ”¯æŒé€šç”¨ä»»åŠ¡ï¼ˆVicuna-80ï¼‰ã€è‡ªæˆ‘è®¤çŸ¥ä»»åŠ¡ã€ç‰¹å®šé¢†åŸŸæµ‹è¯•
- æ”¯æŒäººå·¥æ‰“åˆ†ä¸ GPT-4 æ¯”è¾ƒè¯„ä¼°

---

## ğŸ§± ç¡¬ä»¶éœ€æ±‚å»ºè®®
- è®­ç»ƒæ¨èï¼š

    - 7B LoRA è®­ç»ƒï¼š50GB æ˜¾å­˜

    - 13B LoRA è®­ç»ƒï¼š80GB æ˜¾å­˜

    - æ¨èæ˜¾å¡ï¼šA100 40Gã€H800ã€RTX 6000 Adaã€RTX 4090

æœ¬åœ°éƒ¨ç½²æ¨èï¼š

| æ¨¡å‹ç‰ˆæœ¬ | éƒ¨ç½²æ˜¾å­˜ | æ¨èæ˜¾å¡ |
|----------|-----------|-----------|
| 7B       | â‰¥ 8GiB    | RTX 3060 (12G)ã€RTX A2000 (12G)ã€A10 |
| 13B      | â‰¥ 16GiB   | RTX 4080 (16G)ã€RTX 4090 (24G)ã€A6000ã€L40 |

è®­ç»ƒå»ºè®®ä½¿ç”¨ A100 40Gã€H800ã€RTX 6000 Adaã€‚

---

## ğŸ¤ å‚ä¸è´¡çŒ®

| å§“å | åˆ†å·¥è¯´æ˜ |
|------|----------|
| ç‹ç¥ºæ£® | è´Ÿè´£**å¤©æ–‡é¢†åŸŸçŸ¥è¯†**ã€æ•°å­¦åŸºç¡€è®¡ç®—æ–¹é¢çš„æ¨¡å‹è¯„ä¼°ï¼›**æ„å»ºä¸ä¼˜åŒ–è‡ªæˆ‘è®¤çŸ¥è¯­æ–™åº“** |
| åˆ˜æ“å¤© | ä» Astro-QA æ•°æ®é›†ä¸­**æ•´åˆ 10 ä¸‡æ¡ä¸­æ–‡å¤©æ–‡çŸ¥è¯†**ï¼›**è®­ç»ƒå¹¶å¾®è°ƒæ˜Ÿè¯­è€…-7B ä¸ 13B æ¨¡å‹** |
| é«˜æ¥šçš“ | **æ”¶é›† 10 ä¸‡æ¡æ•°å­¦æ¨ç†è®­ç»ƒè¯­æ–™**ï¼›ååŠ©å®Œæˆæ˜Ÿè¯­è€…-13B æ¨¡å‹çš„è®­ç»ƒæµç¨‹ |
| å‘¨çè½© | åœ¨ Vicuna-80 ä¸­æ–‡/è‹±æ–‡æµ‹è¯•é›†ä¸­**å®Œæˆ 20 æ¡é€šç”¨ä»»åŠ¡çš„äººå·¥è¯„ä¼°**ï¼›æµ‹è¯•å°ç»„æ¨¡å‹è‡ªæˆ‘è®¤çŸ¥èƒ½åŠ› |
| é«˜ç§‹é˜³ | **æ„å»ºè‡ªæˆ‘è®¤çŸ¥ä¸‰å…ƒè¯­æ–™é›†åˆ**ï¼›æ•´åˆå›¢é˜ŸæŠ¥å‘Šä¸æ–‡æ¡£æ’°å†™å†…å®¹ |

---

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢ä¸­ç§‘é™¢è®¡ç®—æ‰€å‘å¸ƒçš„ **BayLing å¼€æºæ¨¡å‹ä¸ GitHub ä»“åº“ (https://github.com/ictnlp/BayLing)** ä¸ºæ˜Ÿè¯­è€…æ¨¡å‹æä¾›äº†å¼ºå¤§çš„åº•åº§ä¸èŒƒå¼æ”¯æŒã€‚
- æ„Ÿè°¢ã€Šé€šç”¨å¤§æ¨¡å‹åŸç†åŠè®­ç»ƒå®è·µã€‹è¯¾ç¨‹æä¾›çš„ç¯å¢ƒã€å¹³å°ä¸æŠ€æœ¯æŒ‡å¯¼ã€‚
- æ„Ÿè°¢æ¯ä¸€ä½å›¢é˜Ÿæˆå‘˜åœ¨è¯­æ–™æ„å»ºã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å®éªŒä¸æ–‡æ¡£æ’°å†™ä¸­åšå‡ºçš„è´¡çŒ®ï¼